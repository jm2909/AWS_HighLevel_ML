{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "This notebook will help to udnerstand and use the comprehend service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role,ModelPackage\n",
    "import re\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some function for basic data cleaning\n",
    "\n",
    "I am taking the analytics vidya's competition data to understand Amazon Comprehend.\n",
    "\n",
    "**Preprocessing Step**\n",
    "\n",
    "1. Remove Hashtags\n",
    "2. Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(text):\n",
    "    \"\"\"\n",
    "        Extract the hashtags from a text\n",
    "        Regular expressions: r\"#(\\w+)\"\n",
    "        \n",
    "        Args:\n",
    "            text: input text (str)\n",
    "        Returns:\n",
    "            hashtags : list\n",
    "            \n",
    "        >>> text = \"\"\n",
    "        >>> get_hashtags(text)\n",
    "        >>>\n",
    "    \n",
    "    \"\"\"\n",
    "    return re.findall(r\"#(\\w+)\", text)\n",
    "\n",
    "def detecturl(text):\n",
    "    \"\"\"\n",
    "        Detect the urls from a text\n",
    "        Regular expressions: \"(?P<url>https?://[^\\s]+)\"\n",
    "        \n",
    "        Args:\n",
    "            text: input text (str)\n",
    "        Returns:\n",
    "            url : str\n",
    "            \n",
    "        >>> text = \"\"\n",
    "        >>> detecturl(text)\n",
    "        >>>\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        return re.search(\"(?P<url>https?://[^\\s]+)\", text).group(\"url\")\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def remove_hashtags(text,hashlist):\n",
    "    \"\"\"\n",
    "        Remove the hastags from the text\n",
    "        \n",
    "        Args:\n",
    "            text: input text (str)\n",
    "            hashlist : output of get_hashtags function (list)\n",
    "        Returns:\n",
    "            text : cleaned text (str)\n",
    "            \n",
    "        >>> text = \"\"\n",
    "        >>> remove_hashtags(text)\n",
    "        >>>\n",
    "    \n",
    "    \"\"\"\n",
    "    for k in hashlist:\n",
    "        text = text.replace(k,'')\n",
    "    return text\n",
    "def clean_punctuation(text):\n",
    "    \"\"\"\n",
    "        Remove the punctuations from the text\n",
    "        Regular expressions: r'[^\\w\\s]'\n",
    "        \n",
    "        Args:\n",
    "            text: input text (str)\n",
    "        Returns:\n",
    "            text : cleaned text (str)\n",
    "            \n",
    "        >>> text = \"\"\n",
    "        >>> clean_punctuation(text)\n",
    "        >>>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub(r'[^\\w\\s]','',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('NLP_train_data.csv')\n",
    "data['hashtags']  = data.tweet.apply(lambda x: get_hashtags(x))\n",
    "data['urls'] = data.tweet.apply(lambda x: detecturl(x))\n",
    "data['cleantext'] = data[['tweet','urls']].apply(lambda x: x['tweet'].replace(x['urls'],''),1)\n",
    "data['cleantext'] = data[['cleantext','hashtags']].apply(lambda x: remove_hashtags(x['cleantext'],x['hashtags']),1)\n",
    "data['cleantext'] = data.cleantext.apply(lambda x: clean_punctuation(x))\n",
    "data['TextLength'] = data.cleantext.apply(lambda x: len(x.strip().split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set aws access key using aws cli or as a configuration file.\n",
    "\n",
    "!aws configure set aws_access_key_id '{your id}'\n",
    "\n",
    "!aws configure set aws_secret_access_key '{your key}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprehend Service**\n",
    "\n",
    "All the output json will be in jsonoutput_comprehend folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client(service_name='comprehend',region_name = 'us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('jsonoutput_comprehend')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What amazing service Apple wont even talk to me about a question I have unless I pay them 1995 for their stupid support\n"
     ]
    }
   ],
   "source": [
    "text = data.cleantext.iloc[4]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction - Single Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(jsonfile,key):\n",
    "    \"\"\"\n",
    "        This function helps to extract relevant contents for 4 different methods.\n",
    "        \n",
    "        1. Entity extraction key : 'Entities'\n",
    "        2. Key phrase extraction key : 'KeyPhrases'\n",
    "        3. Sentiment analyzer key: 'SentimentScore'\n",
    "        3. Sentiment analyzer key: 'SyntaxTokens'\n",
    "        \n",
    "        Supported AWS comprehend methods:\n",
    "        \n",
    "            1. detect_entities\n",
    "            2. detect_key_phrases\n",
    "            3. detect_sentiment\n",
    "            4. detect_syntax\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            jsonfile : jsonfile returns from comprehend services (.json)\n",
    "            key : key of the json file for extraction\n",
    "        \n",
    "        \n",
    "        >>> entity_detection_json = comprehend.detect_entities(Text = text,LanguageCode = 'en')\n",
    "        >>> extract(entity_detection_json,'Entities')\n",
    "        >>> Detected_Entities : Pandas Format\n",
    "            Score    Type    Text    BeginOffset    EndOffset\n",
    "            0.991983    ORGANIZATION    Apple    21    26\n",
    "            0.999853    DATE    1995    90    94\n",
    "    \n",
    "    \"\"\"\n",
    "    if jsonfile['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "        if isinstance(jsonfile[key],dict):\n",
    "            return pd.DataFrame([jsonfile[key]])\n",
    "        else:\n",
    "            return pd.DataFrame(jsonfile[key])\n",
    "    else:\n",
    "        return \"Response code is not 200!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Detected_Entities : Pandas Format\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991983</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>Apple</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999853</td>\n",
       "      <td>DATE</td>\n",
       "      <td>1995</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score          Type   Text  BeginOffset  EndOffset\n",
       "0  0.991983  ORGANIZATION  Apple           21         26\n",
       "1  0.999853          DATE   1995           90         94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_detection_json = comprehend.detect_entities(\n",
    "    Text = text,LanguageCode = 'en')\n",
    "import json\n",
    "with open(\"jsonoutput_comprehend/entity_detection_json.json\",\"w\") as js:\n",
    "    json.dump(entity_detection_json,js)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Detected_Entities : Pandas Format\")\n",
    "extract(entity_detection_json,'Entities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Phrase Extraction - Single Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Phrases  - Pandas format\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995883</td>\n",
       "      <td>amazing service</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.579024</td>\n",
       "      <td>Apple</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>a question</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999994</td>\n",
       "      <td>1995</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score             Text  BeginOffset  EndOffset\n",
       "0  0.995883  amazing service            5         20\n",
       "1  0.579024            Apple           21         26\n",
       "2  1.000000       a question           54         64\n",
       "3  0.999994             1995           90         94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_detection_json = comprehend.detect_key_phrases(\n",
    "    Text = text,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/phase_detection_json.json\",\"w\") as js:\n",
    "    json.dump(entity_detection_json,js)\n",
    "print(\"Key Phrases  - Pandas format\")\n",
    "extract(phrase_detection_json,'KeyPhrases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Extraction - Single Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment scores  - Pandas format\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761463</td>\n",
       "      <td>0.098101</td>\n",
       "      <td>0.051443</td>\n",
       "      <td>0.088993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Positive  Negative   Neutral     Mixed\n",
       "0  0.761463  0.098101  0.051443  0.088993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_detection_json = comprehend.detect_sentiment(\n",
    "    Text = text,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/sentiment_detection_json.json\",\"w\") as js:\n",
    "    json.dump(sentiment_detection_json,js)\n",
    "print(\"Sentiment scores  - Pandas format\")\n",
    "extract(sentiment_detection_json,'SentimentScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax tokens (PoS) Extraction - Single Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax tokens  - Pandas format\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenId</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.7429221868515015}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>amazing</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>{'Tag': 'ADJ', 'Score': 0.9928527474403381}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>service</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>{'Tag': 'NOUN', 'Score': 0.9986752867698669}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>{'Tag': 'PROPN', 'Score': 0.9693880081176758}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wont</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>{'Tag': 'VERB', 'Score': 0.9332540035247803}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>even</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>{'Tag': 'ADV', 'Score': 0.9979731440544128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>talk</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>{'Tag': 'VERB', 'Score': 0.9342613220214844}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>to</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>{'Tag': 'ADP', 'Score': 0.9995973706245422}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>me</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.9999958276748657}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>about</td>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>{'Tag': 'ADP', 'Score': 0.9659994840621948}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>{'Tag': 'DET', 'Score': 0.9999905824661255}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>question</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>{'Tag': 'NOUN', 'Score': 0.9999921321868896}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>I</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.9997640252113342}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>have</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>{'Tag': 'VERB', 'Score': 0.9377665519714355}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>unless</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>{'Tag': 'SCONJ', 'Score': 0.9998996257781982}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>I</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.9999696016311646}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>pay</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>{'Tag': 'VERB', 'Score': 0.999994158744812}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>them</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.999962568283081}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1995</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>{'Tag': 'NUM', 'Score': 0.9998799562454224}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>for</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>{'Tag': 'ADP', 'Score': 0.9983189702033997}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>their</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>{'Tag': 'PRON', 'Score': 0.9999988079071045}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>stupid</td>\n",
       "      <td>105</td>\n",
       "      <td>111</td>\n",
       "      <td>{'Tag': 'ADJ', 'Score': 0.996864378452301}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>support</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>{'Tag': 'NOUN', 'Score': 0.9997339844703674}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TokenId      Text  BeginOffset  EndOffset  \\\n",
       "0         1      What            0          4   \n",
       "1         2   amazing            5         12   \n",
       "2         3   service           13         20   \n",
       "3         4     Apple           21         26   \n",
       "4         5      wont           27         31   \n",
       "5         6      even           32         36   \n",
       "6         7      talk           37         41   \n",
       "7         8        to           42         44   \n",
       "8         9        me           45         47   \n",
       "9        10     about           48         53   \n",
       "10       11         a           54         55   \n",
       "11       12  question           56         64   \n",
       "12       13         I           65         66   \n",
       "13       14      have           67         71   \n",
       "14       15    unless           72         78   \n",
       "15       16         I           79         80   \n",
       "16       17       pay           81         84   \n",
       "17       18      them           85         89   \n",
       "18       19      1995           90         94   \n",
       "19       20       for           95         98   \n",
       "20       21     their           99        104   \n",
       "21       22    stupid          105        111   \n",
       "22       23   support          112        119   \n",
       "\n",
       "                                     PartOfSpeech  \n",
       "0    {'Tag': 'PRON', 'Score': 0.7429221868515015}  \n",
       "1     {'Tag': 'ADJ', 'Score': 0.9928527474403381}  \n",
       "2    {'Tag': 'NOUN', 'Score': 0.9986752867698669}  \n",
       "3   {'Tag': 'PROPN', 'Score': 0.9693880081176758}  \n",
       "4    {'Tag': 'VERB', 'Score': 0.9332540035247803}  \n",
       "5     {'Tag': 'ADV', 'Score': 0.9979731440544128}  \n",
       "6    {'Tag': 'VERB', 'Score': 0.9342613220214844}  \n",
       "7     {'Tag': 'ADP', 'Score': 0.9995973706245422}  \n",
       "8    {'Tag': 'PRON', 'Score': 0.9999958276748657}  \n",
       "9     {'Tag': 'ADP', 'Score': 0.9659994840621948}  \n",
       "10    {'Tag': 'DET', 'Score': 0.9999905824661255}  \n",
       "11   {'Tag': 'NOUN', 'Score': 0.9999921321868896}  \n",
       "12   {'Tag': 'PRON', 'Score': 0.9997640252113342}  \n",
       "13   {'Tag': 'VERB', 'Score': 0.9377665519714355}  \n",
       "14  {'Tag': 'SCONJ', 'Score': 0.9998996257781982}  \n",
       "15   {'Tag': 'PRON', 'Score': 0.9999696016311646}  \n",
       "16    {'Tag': 'VERB', 'Score': 0.999994158744812}  \n",
       "17    {'Tag': 'PRON', 'Score': 0.999962568283081}  \n",
       "18    {'Tag': 'NUM', 'Score': 0.9998799562454224}  \n",
       "19    {'Tag': 'ADP', 'Score': 0.9983189702033997}  \n",
       "20   {'Tag': 'PRON', 'Score': 0.9999988079071045}  \n",
       "21     {'Tag': 'ADJ', 'Score': 0.996864378452301}  \n",
       "22   {'Tag': 'NOUN', 'Score': 0.9997339844703674}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax_detection_json = comprehend.detect_syntax(\n",
    "    Text = text,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/syntax_detection_json.json\",\"w\") as js:\n",
    "    json.dump(syntax_detection_json,js)\n",
    "print(\"Syntax tokens  - Pandas format\")\n",
    "extract(syntax_detection_json,'SyntaxTokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing\n",
    "\n",
    "Please note that all the apis we have used above, we can use the same for batch processing. **Maximum size of a batch = 25**.\n",
    "\n",
    "All the batch processing except language extraction expact that sentences belong to same language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['That  tho   love', 'apple are you seriously so afraid of your profit going into someone elses pocket that you make it to where other chargers arent supported My phone is at 18 and my POS apple charger broke a month after getting the phone Good job Apple you', 'Playing start the party         Carlos A House', 'will be rolling out the   at s day', 'Yes Totally unexpected  Thank you ninong Vicpaul for the    Cant wait for Saturday to get my gift', 'Day 21  my favorite  sammy doo       B River', 'What more do you need', 'So my life is', 'I am so happy i dont have an', 'tjitjil Seriously Mbaak O Noted in mind next time I chew apple p re apel bawang kentang', 'my phone is officially broken i can hear it go off but the screen doesnt work the keyboard is okay though', 'to announce we will have our     on hand  hesterstfair', 'STILL NOT OVER IT        sia', 'now i do love u', 'What would my night be if I didnt drop my phone on my face in bed every night iphone', 'I just that modest  button of  for    httptwitpiccom9jh9o', 'Make de natal  self', 'Now my first tweet by my new smartphone  Xperia  sonyxperia', 'The prices for phones nowadays are like umm yeah let me just cut off this arm for you just so I can have this phone', 'Second shelf on          work working', 'The sweetest things        od', '➊  ➋ RETWEET ➌ FOLLOW ALL WHO RT ➍  ➎ GAIN TODAY   2pg', 'Brooklyn', 'fuck u mean u dont have a 15 inch with anti glare  waste of time', 'Kay since my wifi just went off now back on my iMessage isnt working']\n"
     ]
    }
   ],
   "source": [
    "text_list = data.cleantext.sample(25).apply(lambda x: x.strip()).values.tolist()\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction - Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_df(js,key):\n",
    "    \"\"\"\n",
    "        This function helps to extract relevant contents for 4 different methods for batch processing.\n",
    "        \n",
    "        1. Entity extraction key : 'Entities'\n",
    "        2. Key phrase extraction key : 'KeyPhrases'\n",
    "        3. Sentiment analyzer key: 'SentimentScore'\n",
    "        3. Sentiment analyzer key: 'SyntaxTokens'\n",
    "        \n",
    "        Supported AWS comprehend methods:\n",
    "        \n",
    "            1. detect_entities\n",
    "            2. detect_key_phrases\n",
    "            3. detect_sentiment\n",
    "            4. detect_syntax\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            js : jsonfile returns from comprehend batch services (.json)\n",
    "            key : key of the json file for extraction\n",
    "        \n",
    "        \n",
    "        >>> out_batch_entities = comprehend.batch_detect_entities(TextList = text_list,LanguageCode = 'en')\n",
    "        >>> get_batch_df(out_batch_entities['ResultList'],'Entities')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ent =  pd.DataFrame(js['Entities']) \n",
    "    ent['Line_Number'] = js['Index']\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch_entities = comprehend.batch_detect_entities(\n",
    "    TextList = text_list,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/batch_detect_entities.json\",\"w\") as js:\n",
    "    json.dump(out_batch_entities,js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.794621</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>18</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>167.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.741435</td>\n",
       "      <td>DATE</td>\n",
       "      <td>a month</td>\n",
       "      <td>187.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>Apple</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line_Number     Score          Type     Text  BeginOffset  EndOffset\n",
       "0            1  0.999751  ORGANIZATION    apple          0.0        5.0\n",
       "1            1  0.794621      QUANTITY       18        153.0      155.0\n",
       "2            1  0.993610  ORGANIZATION    apple        167.0      172.0\n",
       "3            1  0.741435          DATE  a month        187.0      194.0\n",
       "4            1  0.994091  ORGANIZATION    Apple        228.0      233.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_entity_df = pd.concat(list(map(lambda x: get_batch_df(x,'Entities'), out_batch_entities['ResultList'])))\n",
    "batch_entity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Phrase Extraction - Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch_phrases = comprehend.batch_detect_key_phrases( TextList = text_list,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/batch_detect_key_phrases.json\",\"w\") as js: \n",
    "    json.dump(out_batch_phrases,js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.794621</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>18</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>167.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.741435</td>\n",
       "      <td>DATE</td>\n",
       "      <td>a month</td>\n",
       "      <td>187.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>Apple</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line_Number     Score          Type     Text  BeginOffset  EndOffset\n",
       "0            1  0.999751  ORGANIZATION    apple          0.0        5.0\n",
       "1            1  0.794621      QUANTITY       18        153.0      155.0\n",
       "2            1  0.993610  ORGANIZATION    apple        167.0      172.0\n",
       "3            1  0.741435          DATE  a month        187.0      194.0\n",
       "4            1  0.994091  ORGANIZATION    Apple        228.0      233.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_phrase_df = pd.concat(list(map(lambda x: get_batch_df(x,'KeyPhrases'), out_batch_entities['ResultList'])))\n",
    "batch_phrase_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax Extraction - Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch_syntax = comprehend.batch_detect_syntax(\n",
    "    TextList = text_list,LanguageCode = 'en')\n",
    "with open(\"jsonoutput_comprehend/batch_detect_syntax.json\",\"w\") as js:\n",
    "    json.dump(out_batch_syntax,js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_Number</th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.794621</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>18</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>apple</td>\n",
       "      <td>167.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.741435</td>\n",
       "      <td>DATE</td>\n",
       "      <td>a month</td>\n",
       "      <td>187.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>Apple</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line_Number     Score          Type     Text  BeginOffset  EndOffset\n",
       "0            1  0.999751  ORGANIZATION    apple          0.0        5.0\n",
       "1            1  0.794621      QUANTITY       18        153.0      155.0\n",
       "2            1  0.993610  ORGANIZATION    apple        167.0      172.0\n",
       "3            1  0.741435          DATE  a month        187.0      194.0\n",
       "4            1  0.994091  ORGANIZATION    Apple        228.0      233.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax_df = pd.concat(list(map(lambda x: get_batch_df(x,'SyntaxTokens'), out_batch_entities['ResultList'])))\n",
    "syntax_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
